{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#### Kaggle: https://www.kaggle.com/c/sai-vessel-segmentation2"],"metadata":{"id":"Jd6y8yx5Ehow"}},{"cell_type":"code","metadata":{"id":"M2GkgAqNh_Ze"},"source":["import os\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from glob import glob\n","from tqdm.auto import tqdm\n","import imgaug\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","import torch\n","from torch import nn\n","import torchvision\n","import torchsummary\n","\n","torch.__version__, imgaug.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2OPV-lkieSh"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cz487p6sizBy"},"source":["#### Download data"]},{"cell_type":"code","metadata":{"id":"KDk_laoliuYc"},"source":["# download dataset from https://drive.google.com/file/d/1JILW10sr40CRTLiuA1mf__5GBtMDF9xc/view?usp=sharing\n","!pip install --upgrade gdown\n","!gdown --id 1JILW10sr40CRTLiuA1mf__5GBtMDF9xc --output vessel_seg.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"boKAzyiii1nv"},"source":["# unzip file\n","!unzip -q vessel_seg.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ghmV5Y0i61d"},"source":["#### Data Analysis\n","\n","\n","---\n","\n","all\n","\n","\n","*   train/\n","    *   id1_training.tif\n","    *   id1**_manual1**.gif\n","    *   id2_training.tif\n","    *   id2**_manual1**.gif\n","    *   ...\n","*   test/\n","    *   ...\n","\n"]},{"cell_type":"code","metadata":{"id":"lSGz8Suzi5TT"},"source":["# read img and mask\n","img_paths = sorted(glob('all/train/*.tif'))\n","img_path = img_paths[0]\n","mask_path = img_path.replace('_training.tif', '_manual1.gif')\n","\n","print('img path: ', img_path)\n","print('mask path:',  mask_path)\n","\n","img = cv2.imread(img_path)[:, :, ::-1]\n","mask = Image.open(mask_path)\n","mask = np.array(mask)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mUJ4MLj7oNz2"},"source":["Image shape: (H, W, C)\n","\n","*   C: 3 RGB channels\n","\n","Mask  shape: (H, W)\n","* 0: background\n","* 255: vessel"]},{"cell_type":"code","metadata":{"id":"HvkFYpk_jw3E"},"source":["# show image\n","plt.figure(figsize=(20, 5))\n","plt.subplot(1,2,1)\n","plt.imshow(img)\n","plt.subplot(1,2,2)\n","plt.imshow(mask)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FeHU3oqkcuo"},"source":["img.shape, mask.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oT_3y1iDpJ5b"},"source":["# Calculate tumor pixel\n","values, counts = np.unique(mask, return_counts=True)\n","values, counts"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DGKkfEKrp7Gi"},"source":["# Dataset & Dataloader\n"]},{"cell_type":"code","metadata":{"id":"B3qAbKsrv4vC"},"source":["IMG_SIZE = 512\n","BS = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6iA0hkrp9Lm"},"source":["class VesselDataset(torch.utils.data.Dataset):\n","    def __init__(self, img_paths, img_size, mode, augmentation=False):\n","        self.img_paths = img_paths\n","        self.mask_paths = [m_path.replace('training.tif', 'manual1.gif') for m_path in self.img_paths]\n","        self.img_size = img_size\n","        self.mode = mode\n","        # Augmentation\n","        self.augmentation = augmentation\n","        self.augmentor = imgaug.augmenters.Sequential([\n","            imgaug.augmenters.Fliplr(0.5), # 50% horizontal flip\n","            imgaug.augmenters.Affine(\n","                rotate=(-45, 45), # random rotate -45 ~ +45 degree\n","                shear=(-16,16), # random shear -16 ~ +16 degree\n","                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)} # scale x, y: 80%~120%\n","            ),\n","        ])\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_paths[idx]\n","        img = cv2.imread(img_path)[:, :, ::-1]\n","        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) # (IMG_SIZE, IMG_SIZE, 3)\n","        # Normalize Image\n","        img = img / 255. # 0~255 -> 0~1\n","\n","        if self.mode != 'test':\n","            mask_path = self.mask_paths[idx]\n","            mask = np.array(Image.open(mask_path))\n","            mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE)) # (IMG_SIZE, IMG_SIZE)\n","            # Binarize mask from [0~255] to (0 or 1)\n","            mask = np.where(mask<1, 0, 1).astype(np.int16)\n","\n","            # Augment mask by imgaug\n","            if self.augmentation:\n","                # to imgaug data class\n","                mask = imgaug.augmentables.segmaps.SegmentationMapsOnImage(mask,\n","                                                                    shape=mask.shape)\n","                # augment img & mask \"simultaneously\"\n","                img, mask = self.augmentor(image=img, segmentation_maps=mask)\n","                mask = mask.get_arr() # to np.ndarray\n","\n","            # 1. Convert to PyTorch Tensor\n","            # 2. Channel last to first: (H, W, C) -> (C, H, W)\n","            # Tensor datatype:\n","            # Img: float, Mask: long\n","            img = torch.tensor(img, dtype=torch.float).permute(2, 0, 1)\n","            mask = torch.tensor(mask, dtype=torch.long)\n","            return img, mask\n","        else:\n","            img_tensor = torch.tensor(img, dtype=torch.float).permute(2, 0, 1)\n","            return img_tensor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LinYJODA2Zks"},"source":["all_paths = sorted(glob('all/train/*.tif'))\n","test_paths = sorted(glob('all/test/*.tif'))\n","train_paths, val_paths = train_test_split(all_paths, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"igaH8dLYzJf1"},"source":["train_ds = VesselDataset(train_paths, IMG_SIZE, 'train', augmentation=True)\n","val_ds = VesselDataset(val_paths, IMG_SIZE, 'val')\n","test_ds = VesselDataset(test_paths, IMG_SIZE, 'test')\n","\n","# https://pytorch.org/docs/stable/data.html\n","NUM_WORKERS = 2 # > 0 to accelerate loading data by muli-process\n","\n","train_loader = torch.utils.data.DataLoader(train_ds, BS, shuffle=True, num_workers=NUM_WORKERS)\n","val_loader = torch.utils.data.DataLoader(val_ds, BS, num_workers=NUM_WORKERS)\n","test_loader = torch.utils.data.DataLoader(test_ds, BS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i84xSmw0VY4Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RqWyOJ66bUm1"},"source":["Visulize data"]},{"cell_type":"code","metadata":{"id":"vFRg-oTT6dHD"},"source":["img, mask = train_ds[0] # take 1 data\n","print('img.shape: ', img.shape, '\\nmask.shape: ', mask.shape)\n","img = img.numpy().transpose(1, 2, 0) # (C, H, W) -> (H, W, C)\n","mask = mask.numpy().squeeze() # (1, H, W) -> (H, W)\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.imshow(img)\n","plt.subplot(1, 2, 2)\n","plt.imshow(mask)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dreRbVHDeOpF"},"source":["#### Build Model"]},{"cell_type":"code","metadata":{"id":"-fwuxuQNeQ9b"},"source":["# Basic Conv block\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ConvBlock, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","    def __call__(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n","        super(UNet, self).__init__()\n","        # Encoder\n","        self.encoder1 = ConvBlock(in_channels, init_features) # (3, H, W) -> (32, H, W)\n","        self.pool1 = nn.MaxPool2d(2)\n","        self.encoder2 = ConvBlock(init_features, init_features*2) # (32, H/2, W/2) -> (64, H/2, W/2)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.encoder3 = ConvBlock(init_features*2, init_features*4) # (64, H/4, W/4) -> (128, H/4, W/4)\n","        self.pool3 = nn.MaxPool2d(2)\n","        self.encoder4 = ConvBlock(init_features*4, init_features*8) # (128, H/8, W/8) -> (256, H/8, W/8)\n","        self.pool4 = nn.MaxPool2d(2)\n","        self.encoder5 = ConvBlock(init_features*8, init_features*16) # (256, H/16, W/16) -> (512, H/16, W/16)\n","\n","        # Decoder\n","        self.upconv4 = nn.ConvTranspose2d(init_features*16, # (512, H/16, W/16) -> (256, H/8, W/8)\n","                          init_features*8,\n","                          kernel_size=2, stride=2)\n","        self.decoder4 = ConvBlock(init_features*8*2, init_features*8)\n","        self.upconv3 = nn.ConvTranspose2d(init_features*8, # (256, H/8, W/8) -> (128, H/4, W/4)\n","                          init_features*4,\n","                          kernel_size=2, stride=2)\n","        self.decoder3 = ConvBlock(init_features*4*2, init_features*4)\n","        self.upconv2 = nn.ConvTranspose2d(init_features*4, # (128, H/4, W/4) -> (64, H/2, W/2)\n","                          init_features*2,\n","                          kernel_size=2, stride=2)\n","        self.decoder2 = ConvBlock(init_features*2*2, init_features*2)\n","        self.upconv1 = nn.ConvTranspose2d(init_features*2, # (62, H/2, W/2) -> (32, H, W)\n","                          init_features,\n","                          kernel_size=2, stride=2)\n","        self.decoder1 = ConvBlock(init_features*2, init_features)\n","        # Output (head): classification for each pixel, C=2\n","        self.output = nn.Conv2d(\n","            init_features,\n","            out_channels=out_channels,\n","            kernel_size=1) # (32, H, W) -> (2, H, W)\n","\n","    def forward(self, x):\n","        # Encoder\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool1(enc1))\n","        enc3 = self.encoder3(self.pool2(enc2))\n","        enc4 = self.encoder4(self.pool3(enc3))\n","        bottleneck = self.encoder5(self.pool4(enc4))\n","\n","        # Decoder\n","        # (BS, 256, H/8, W/8) + (BS, 256, H/8, W/8) -> (BS, 512, H/8, W/8)\n","        x = torch.cat((self.upconv4(bottleneck), enc4), dim=1)\n","        x = self.decoder4(x)\n","\n","        x = torch.cat((self.upconv3(x), enc3), dim=1)\n","        x = self.decoder3(x)\n","\n","        x = torch.cat((self.upconv2(x), enc2), dim=1)\n","        x = self.decoder2(x)\n","\n","        x = torch.cat((self.upconv1(x), enc1), dim=1)\n","        x = self.decoder1(x)\n","\n","        x = self.output(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27kiBA-Hbmbz"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","# build model to GPU\n","model = UNet(in_channels=3,\n","             out_channels=2,\n","             init_features=32).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training\n","\n","TODO"],"metadata":{"id":"hoGAF0JLGZJh"}},{"cell_type":"markdown","source":["Kaggle submission"],"metadata":{"id":"AJ7C_P3BGXCY"}},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"best.pth\"))"],"metadata":{"id":"qUs9FzjjOdrH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGHJBErR8rZ-"},"source":["# make prediction\n","outputs = []\n","with torch.no_grad():\n","    for imgs in test_loader:\n","        imgs = imgs.to(device)\n","        y_preds = model(imgs).cpu().numpy()\n","        y_preds = np.argmax(y_preds, axis=1)\n","        y_preds = np.expand_dims(y_preds, axis=-1)\n","\n","        for y_pred in y_preds:\n","            dots = np.where(y_pred.flatten() == 1)[0]\n","            run_lengths = []\n","            prev = -2\n","            for b in dots:\n","                if (b > prev +1):\n","                    run_lengths.extend((b+1,0))\n","                run_lengths[-1] += 1\n","                prev = b\n","            output = ' '.join([str(r) for r in run_lengths])\n","            outputs.append(output)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEmkCfO46Nw4"},"source":["# Create submission file\n","df = pd.DataFrame(columns=['Id', 'Predicted'])\n","df['Id'] = [str(i) for i in range(20)]\n","df['Predicted'] = outputs\n","df.to_csv('submission.csv', index=None)\n","df"],"execution_count":null,"outputs":[]}]}