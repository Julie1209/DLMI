{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPeMksNno4Nj7Z8ttc7Ckyh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://github.com/taipingeric/fusionlab\n","\n","source code: https://github.com/taipingeric/fusionlab/blob/main/fusionlab/segmentation/resunet/resunet.py"],"metadata":{"id":"CgQAuCmXYNXk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qTh32NyYJQg"},"outputs":[],"source":["!pip install fusionlab"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from fusionlab.segmentation.base import SegmentationModel\n","from fusionlab.utils import autopad\n","from fusionlab.layers.factories import ConvND, ConvT, BatchNorm\n","\n","\n","\n","class ResUNet(SegmentationModel):\n","    def __init__(self, cin, num_cls, base_dim, spatial_dims=2):\n","        super().__init__()\n","        self.encoder = Encoder(cin, base_dim, spatial_dims)\n","        self.bridger = Bridger()\n","        self.decoder = Decoder(base_dim, spatial_dims)\n","        self.head = Head(base_dim, num_cls, spatial_dims)\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, cin, base_dim, spatial_dims=2):\n","        super().__init__()\n","        dims = [base_dim * (2 ** i) for i in range(4)]\n","        self.stem = Stem(cin, dims[0], spatial_dims)\n","        self.stage1 = ResConv(dims[0], dims[1], spatial_dims, stride=2)\n","        self.stage2 = ResConv(dims[1], dims[2], spatial_dims, stride=2)\n","        self.stage3 = ResConv(dims[2], dims[3], spatial_dims, stride=2)\n","\n","    def forward(self, x):\n","        s0 = self.stem(x)\n","        s1 = self.stage1(s0)\n","        s2 = self.stage2(s1)\n","        s3 = self.stage3(s2)\n","        return [s0, s1, s2, s3]\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, base_dim, spatial_dims=2):\n","        \"\"\"\n","        Base UNet decoder\n","        Args:\n","            base_dim (int): output dim of deepest stage output or input channels\n","        \"\"\"\n","        super().__init__()\n","        dims = [base_dim*(2**i) for i in range(4)]\n","        self.d3 = DecoderBlock(dims[3], dims[2], spatial_dims)\n","        self.d2 = DecoderBlock(dims[2], dims[1], spatial_dims)\n","        self.d1 = DecoderBlock(dims[1], dims[0], spatial_dims)\n","\n","    def forward(self, x):\n","        s0, s1, s2, s3 = x\n","\n","        x = self.d3(s3, s2)\n","        x = self.d2(x, s1)\n","        x = self.d1(x, s0)\n","        return x\n","\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, cin, cout, spatial_dims=2):\n","        super().__init__()\n","        self.upsample = ConvT(spatial_dims, cin, cout, 2, stride=2)\n","        self.conv = ResConv(cout*2, cout, spatial_dims, 1)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.upsample(x1)\n","        x = torch.cat([x1, x2], dim=1)\n","        return self.conv(x)\n","\n","\n","class Bridger(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        outputs = [nn.Identity()(i) for i in x]\n","        return outputs\n","\n","\n","class Stem(nn.Module):\n","    def __init__(self, cin, cout, spatial_dims=2):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            ConvND(spatial_dims, cin, cout, 3, padding=autopad(3)),\n","            BatchNorm(spatial_dims, cout),\n","            nn.ReLU(),\n","            ConvND(spatial_dims, cout, cout, 3, padding=autopad(3)),\n","        )\n","        self.skip = nn.Sequential(\n","            ConvND(spatial_dims, cin, cout, 3, padding=autopad(3)),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x) + self.skip(x)\n","\n","\n","class ResConv(nn.Module):\n","    def __init__(self, cin, cout, spatial_dims=2, stride=1):\n","        super().__init__()\n","\n","        self.conv = nn.Sequential(\n","            BatchNorm(spatial_dims, cin),\n","            nn.ReLU(),\n","            ConvND(spatial_dims, cin, cout, 3, stride, padding=autopad(3)),\n","            BatchNorm(spatial_dims, cout),\n","            nn.ReLU(),\n","            ConvND(spatial_dims, cout, cout, 3, padding=autopad(3)),\n","        )\n","        self.skip = nn.Sequential(\n","            ConvND(spatial_dims, cin, cout, 3, stride=stride, padding=autopad(3)),\n","            BatchNorm(spatial_dims, cout),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x) + self.skip(x)\n","\n","\n","class Head(nn.Sequential):\n","    def __init__(self, cin, cout, spatial_dims):\n","        \"\"\"\n","        Basic conv head\n","        :param int cin: input channel\n","        :param int cout: output channel\n","        \"\"\"\n","        conv = ConvND(spatial_dims, cin, cout, 1)\n","        super().__init__(conv)"],"metadata":{"id":"mp0uPnnTYMs0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["H = W = 512\n","cout = 64\n","inputs = torch.rand((1, 3, H, W))\n","\n","model = ResUNet(3, 2, cout)\n","output = model(inputs)\n","print(output.shape)"],"metadata":{"id":"svw7q106YX2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ug7-ePY3YjrD"},"execution_count":null,"outputs":[]}]}