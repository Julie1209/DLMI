{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7JqIcnWvwMpc"},"source":["# Basic module\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm # progress bar\n","\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LsiyFhmR_2N"},"source":["# print version of PyTorch\n","torch.__version__, torchvision.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXajqeGESoSn"},"source":["#### Prepare CIFAR10 Dataset\n","\n","*   torch vision datasets: https://pytorch.org/vision/stable/datasets.html\n","*   CIFAR10 label\n","\n","0: airplane\n","1: automobile\n","2: bird\n","3: cat\n","4: deer\n","5: dog\n","6: frog\n","7: horse\n","8: ship\n","9: truck"]},{"cell_type":"code","metadata":{"id":"gDg9Aq-aSCNF"},"source":["# Define Parameters\n","NUM_CLASS = 10\n","# Class name and class mapping\n","class_names = [\n","    'airplane',\n","    'automobile',\n","    'bird',\n","    'cat',\n","    'deer',\n","    'dog',\n","    'frog',\n","    'horse',\n","    'ship',\n","    'truck'\n","]\n","class_map = {cls: i for i, cls in enumerate(class_names)}\n","print(class_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### torch.utils.data.Dataset\n","\n","https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset\n","\n","*   讀取**1**筆資料\n","*   輸出torch.Tensor (張量)\n","* Datasets provided by torchvision https://pytorch.org/vision/stable/datasets.html\n"],"metadata":{"id":"moN1UGPNwBXR"}},{"cell_type":"code","metadata":{"id":"c0QABVe3VT49"},"source":["# Download dataset\n","train_ds = torchvision.datasets.CIFAR10('data', # saved path\n","    train=True, # training or testing set\n","    download=True # download dataset from internet\n",")\n","val_ds = torchvision.datasets.CIFAR10('data',\n","    train=False,\n","    download=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1SDBy2lWFd3"},"source":["# 資料筆數\n","print('Number of training   samples:', len(train_ds))\n","print('Number of validation samples:', len(val_ds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aSl_QHt8WWIa"},"source":["# 隨機取出1筆資料\n","idx = np.random.randint(low=0, high=len(train_ds))\n","img, label = train_ds[idx]\n","\n","print(idx)\n","print(type(img), type(label))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1zAuBoFQXEZn"},"source":["# Convert to np.ndarray and show image\n","img_np = np.array(img)\n","print('img shape: ', img_np.shape)\n","print('label: ', label)\n","print('class name: ', class_names[label])\n","plt.imshow(img_np)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0zMyLJrtZyyE"},"source":["#### Data Proprocess\n","\n","**transforms.ToTensor()**\n","\n","1.   PIL.Image to torch.FloatTensor (張量)\n","  \n","    *   Input: PIL Image or numpy.ndarray (H, W, C) in the range [0, 255]\n","    *   Output: torch.FloatTensor (C, H, W) in the range [0.0, 1.0]\n","\n","2.   TODO: 資料擴增, ... etc\n","\n","**NOTE**: PyTorch 要求通道數在前的形式 (C, H, W)\n"]},{"cell_type":"code","metadata":{"id":"5qMzb9CKZoY7"},"source":["preprocess = transforms.Compose([\n","    transforms.ToTensor(), # Convert PIL.Image or np.array to torch.Tensor\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38oH2kqAb02w"},"source":["# Build dataset with data preprocess\n","train_ds = torchvision.datasets.CIFAR10('data',\n","    train=True,\n","    download=True,\n","    transform=preprocess # 前處理\n",")\n","val_ds = torchvision.datasets.CIFAR10('data',\n","    train=False,\n","    download=True,\n","    transform=preprocess # 前處理\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9WPxmL-dBDW"},"source":["#### Dataset + DataLoader\n","\n","**torch.utils.data.DataLoader**: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n","\n","* 組成批次(**batch**)\n","* 資料取樣\n","* 讀取順序 (shuffle)"]},{"cell_type":"code","metadata":{"id":"b4dGZE1adAS7"},"source":["# 使用 DataLoader 讀取批次資料\n","BATCH_SIZE = 1024\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_ds,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True, # 訓練每輪結束打亂順序\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_ds,\n","    batch_size=BATCH_SIZE\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["檢查資料shape\n","\n","N: 批次數量 (batch)\n","\n","C: 通道數\n","\n","H: 高度\n","\n","W: 寬度\n","\n","**PyTorch use channel first !**"],"metadata":{"id":"wYt-k517xcUA"}},{"cell_type":"code","metadata":{"id":"W8M240hdc-_d"},"source":["for x, y in train_dataloader:\n","    print(\"type \", type(x), type(y))\n","    print(\"Shape of x (N, C, H, W): \", x.shape, x.dtype)\n","    print(\"Shape of y (N, ): \", y.shape, y.dtype)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 取出批次的第0筆顯示\n","plt.imshow(x[0].permute(1, 2, 0)) # (C H W) -> (H W C)\n","plt.title(str(y[0]))\n","plt.show()"],"metadata":{"id":"LkRyhzfDgYhc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8STKvep1eC4v"},"source":["#### Build Model"]},{"cell_type":"code","metadata":{"id":"avl7U7gSe64u"},"source":["# 取得現有硬體 ('GPU', 'CPU')\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")\n","\n","IMG_SIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["定義模型"],"metadata":{"id":"1G09m9PSMB1g"}},{"cell_type":"code","source":["# 序列化模型: 一層一層直接連接\n","model = nn.Sequential(\n","    nn.Flatten(), # (3, 32, 32) -> (3*32*32, )\n","    nn.Linear(\n","        in_features=IMG_SIZE*IMG_SIZE*3,\n","        out_features=64), # (C*H*W) -> (64)\n","    nn.ReLU(),\n","    nn.Linear(64, 128), # (64) -> (128)\n","    nn.ReLU(),\n","    nn.Linear(128, 128),\n","    nn.ReLU(),\n","    nn.Linear(128, NUM_CLASS), # (128) -> NUM_CLASS\n",")\n","model = model.to(device)"],"metadata":{"id":"utPUwXW1WKiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9fUwxRZfJL3"},"source":[" # 繼承 nn.Module\n","class NeuralNet(nn.Module):\n","    def __init__(self):\n","        # 網路層初始化\n","        super().__init__()\n","        self.flatten = nn.Flatten() # (C, H, W) -> (C*H*W)\n","        self.base_model = nn.Sequential(\n","            nn.Linear(in_features=IMG_SIZE*IMG_SIZE*3, out_features=64), # (C*H*W) -> (64)\n","            nn.ReLU(),\n","            nn.Linear(64, 128), # (64) -> (128)\n","            nn.ReLU(),\n","            nn.Linear(128, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, NUM_CLASS), # (128) -> (NUM_CLASS)\n","        )\n","    def forward(self, x):\n","        # forward函式定義輸入的資料張量該用如何運算\n","        # 輸入資料x: (bs, 3, 32, 32)\n","        # 輸入模型都是torch.Tensor\n","        # 且都帶有批次數量的維度 batch_size\n","\n","        x = self.flatten(x)\n","        # flatten: (bs, 3, 32, 32) -> (bs, 3072)\n","        logits = self.base_model(x)\n","        # base_model: (bs, 3072) -> (bs, 10)\n","\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVImZHyCgeDy"},"source":["# 初始化模型，移到device\n","model = NeuralNet().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wivbMuaEwMpp"},"source":["print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vtOqbCgkd9PZ"},"source":["#### 訓練(學習): 最佳化模型參數"]},{"cell_type":"code","source":["# 損失函數: 計算誤差\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"RMz2F_uilfER"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uNNVOuzhhTOj"},"source":["# 優化器: 更新模型參數\n","optimizer = torch.optim.SGD(\n","    params=model.parameters(), # 要最佳化的模型參數\n","    lr=1e-1, # learning rate(學習率): 1e-1, 1e-2, 1e-3 ...\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6foJpLOjmYN"},"source":["def train_epoch(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset) # 資料總數\n","    num_batches = len(dataloader) # 切成批次數\n","\n","    model.train() # 模型轉成訓練模式\n","    epoch_loss, epoch_correct = 0, 0\n","\n","    # 依序取出每批資料\n","    for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n","        x, y = x.to(device), y.to(device) # 資料搬到device\n","\n","        # 資料丟到模型預測\n","        pred = model(x)\n","        # 計算損失\n","        loss = loss_fn(pred, y)\n","\n","        optimizer.zero_grad() # 將過去累積梯度歸零\n","        loss.backward() # 透過loss反向傳播計算梯度\n","        optimizer.step() # 更新模型參數\n","\n","        # 寫紀錄\n","        epoch_loss += loss.item() # tensor -> python value\n","        # pred: (N, Class)\n","        # 計算類別最大值位置(index)是否與解答相同, 統計總數\n","        epoch_correct += (pred.argmax(dim=1) == y).sum().item()\n","\n","    # 計算平均loss, Accuracy\n","    return epoch_loss/num_batches, epoch_correct/size\n","\n","def test_epoch(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset) # number of samples\n","    num_batches = len(dataloader) # batches per epoch\n","\n","    model.eval() # 模型轉成測試模式\n","    epoch_loss, epoch_correct = 0, 0\n","\n","    # 測試時不需要計算梯度\n","    with torch.no_grad():\n","        for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n","            x, y = x.to(device), y.to(device)\n","            pred = model(x)\n","            loss = loss_fn(pred, y)\n","            epoch_loss += loss.item()\n","            epoch_correct += (pred.argmax(1) == y).sum().item()\n","\n","    return epoch_loss/num_batches, epoch_correct/size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpXLEk2HiLPi"},"source":["EPOCHS = 100 # 訓練總回合數, 每一回合都看完所有資料一遍\n","logs = {\n","    'train_loss': [], 'train_acc': [],\n","    'val_loss': [], 'val_acc': []\n","}\n","for epoch in tqdm(range(EPOCHS)):\n","    train_loss, train_acc = train_epoch(train_dataloader, model, loss_fn, optimizer)\n","    val_loss, val_acc = test_epoch(val_dataloader, model, loss_fn)\n","\n","    print(f'EPOCH: {epoch} \\\n","    train_loss: {train_loss:.4f}, train_acc: {train_acc:.3f} \\\n","    val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f} ')\n","\n","    logs['train_loss'].append(train_loss)\n","    logs['train_acc'].append(train_acc)\n","    logs['val_loss'].append(val_loss)\n","    logs['val_acc'].append(val_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rvInhyibpdiY"},"source":["#### Logs"]},{"cell_type":"code","metadata":{"id":"guBMgShGz7jq"},"source":["# Plot loss curve\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.title('Loss')\n","plt.plot(logs['train_loss'])\n","plt.plot(logs['val_loss'])\n","plt.legend(['train_loss', 'val_loss'])\n","# plot acc\n","plt.subplot(1, 2, 2)\n","plt.title('Accuracy')\n","plt.plot(logs['train_acc'])\n","plt.plot(logs['val_acc'])\n","plt.legend(['train_acc', 'val_acc'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kIvqVEbiuAqz"},"source":["#### Save Model"]},{"cell_type":"markdown","source":["Saving & Loading Model (weights only)\n","\n","**Recommended**"],"metadata":{"id":"aN0b_DPT1CsC"}},{"cell_type":"code","source":["# 取得模型參數\n","model.state_dict()"],"metadata":{"id":"Z9y9wlXgDXsf"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAWJyTLWt-nE"},"source":["PATH = './model_weights.pth' # .pt\n","# 存參數\n","torch.save(model.state_dict(), PATH)\n","\n","# 讀參數\n","model.load_state_dict(torch.load(PATH))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saving & Loading Model (entire model)"],"metadata":{"id":"YM2J5jT11J78"}},{"cell_type":"code","source":["MODEL_PATH = './model.pth'\n","# 存模型\n","torch.save(model, MODEL_PATH)\n","# 讀模型\n","model = torch.load(MODEL_PATH)"],"metadata":{"id":"RS9F6zW51OZ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4h_wOV5WuCnb"},"source":["#### Evaluation"]},{"cell_type":"code","metadata":{"id":"9MT2u1TGuMoF"},"source":["# load model\n","model = NeuralNet()\n","model.load_state_dict(torch.load(PATH)) # 讀取參數\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# take first 10 images\n","n = 10\n","for (images, labels) in val_dataloader:\n","    images, labels = images[:n], labels[:n]\n","    images_grid = torchvision.utils.make_grid(images[:n])\n","    images_grid = images_grid.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n","    plt.imshow(images_grid.numpy())\n","    break"],"metadata":{"id":"9PMbgz8g-Vz8"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9iXXH_pt0nl"},"source":["# take first 2 images\n","n = 2\n","for (images, labels) in val_dataloader:\n","    images, labels = images[:n], labels[:n]\n","    break\n","\n","# Predict by model\n","with torch.no_grad():\n","    pred = model(images) # predict logits\n","print('raw_prediction logits', pred, pred.shape, sep=\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_softmax = nn.Softmax(dim=1)(pred) # 模型輸出轉乘機率值\n","print('prediction after softmax', pred_softmax, pred_softmax.shape, sep=\"\\n\")"],"metadata":{"id":"W_-AAW6w_c--"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NenCAHfduumi"},"source":["# max_prob: 每一筆資料最大機率值\n","# predicted_cls: 最大值idx\n","max_prob, predicted_cls = torch.max(pred_softmax, dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_cls = pred_softmax.argmax(dim=1)"],"metadata":{"id":"ygulA8Hd_j7W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_cls"],"metadata":{"id":"SAjL_q7K_p4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpISPISQvrtd"},"source":["print('GroundTruth: ', ' '.join(class_names[labels[j]] for j in range(n)))\n","print('Prediction: ', ' '.join(class_names[predicted_cls[j]] for j in range(n)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"miysWGOOlaoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yv0xgdSKgxXt"},"source":["# 使用 torchsummary 顯示模型架構\n","import torchsummary\n","\n","torchsummary.summary(\n","    model.to(device), # 模型\n","    input_size=(3, 32, 32) # 一筆輸入資料形狀\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 使用 torchinfo 顯示模型架構\n","!pip install torchinfo\n","\n","import torchinfo\n","torchinfo.summary(\n","    model,\n","    input_size=(BATCH_SIZE, 3, 32, 32)\n",")"],"metadata":{"id":"5Wnn17WKurLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MOHZ13RqIfjn"},"execution_count":null,"outputs":[]}]}