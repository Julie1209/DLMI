{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1uRMwvHCxgII3xmibiS27STQDoedzawNk","authorship_tag":"ABX9TyMOTNtgvNbcSuoASBRsvHF6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#### YOLOv7"],"metadata":{"id":"pgWkA2DYjjxz"}},{"cell_type":"markdown","source":["下載github yolov7 repo\n","\n","* 官方：https://github.com/WongKinYiu/yolov7.git\n","* 我Fork版本有些修改：https://github.com/taipingeric/yolov7.git"],"metadata":{"id":"RfioacRYQR3-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4PK3dhp8Tno","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706532434577,"user_tz":-480,"elapsed":5897,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"e924d167-fd91-4f54-bbb1-a9f019cb5a82"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 500, done.\u001b[K\n","remote: Total 500 (delta 0), reused 0 (delta 0), pack-reused 500\u001b[K\n","Receiving objects: 100% (500/500), 35.76 MiB | 8.30 MiB/s, done.\n","Resolving deltas: 100% (260/260), done.\n"]}],"source":["# download github repo\n","# !git clone https://github.com/WongKinYiu/yolov7.git\n","!git clone https://github.com/taipingeric/yolov7.git"]},{"cell_type":"markdown","source":["#### Download dataset\n","\n","BCCD: https://public.roboflow.com/object-detection/bccd"],"metadata":{"id":"V_jBTUcUnkGZ"}},{"cell_type":"code","source":["# download Blood Cell dataset\n","!pip install --upgrade gdown\n","!gdown --fuzzy '1EjOsWZTtqVCU4ZPDAl5qmuf0EhUMEaWT' -O dataset.zip\n","# unzip dataset\n","!unzip -q dataset.zip"],"metadata":{"id":"xl_VqIiEyVoZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706532466740,"user_tz":-480,"elapsed":14545,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"ea643b9f-d534-4f46-d24d-24ffedaa5218"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n","Collecting gdown\n","  Downloading gdown-5.0.1-py3-none-any.whl (16 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.7.3\n","    Uninstalling gdown-4.7.3:\n","      Successfully uninstalled gdown-4.7.3\n","Successfully installed gdown-5.0.1\n","Downloading...\n","From: https://drive.google.com/uc?id=1EjOsWZTtqVCU4ZPDAl5qmuf0EhUMEaWT\n","To: /content/dataset.zip\n","100% 8.02M/8.02M [00:00<00:00, 48.4MB/s]\n"]}]},{"cell_type":"markdown","source":["#### YOLOv7 支援格式1\n","\n","*   train\n","    * images\n","        * img1.jpg\n","    * labels\n","        * img1.txt\n","*   valid\n","    * 同train\n","*   test\n","    * 同train\n","\n","\n","txt格式 (YOLOv5)\n","\n","**class id, x, y, width, height**\n","\n","x,y,w,h 皆為normalized數值 0~1\n","```\n","0 0.0515 0.0251 0.0710 0.0498\n","1 0.3182 0.0465 0.0735 0.0902\n","1 0.4197 0.0535 0.0655 0.0997\n","```\n","\n","**yolov7/data/coco.yaml**\n","```yaml\n","train: ../train/images # 訓練圖片資料夾\n","val: ../valid/images # 驗證圖片資料夾\n","test: ../test/images # 測試圖片資料夾 (Optional)\n","\n","# number of classes\n","nc: 3 # 類別數\n","\n","# class names\n","names: ['Platelets', 'RBC', 'WBC']\n","```"],"metadata":{"id":"i1EA3UOwnuEp"}},{"cell_type":"markdown","source":["#### YOLOv7 支援格式2\n","\n","\n","/coco128\n","*   images\n","    * train2017\n","        * img1.jpg\n","        * img2.jpg\n","    * val2017\n","        * img3.jpg\n","*   labels\n","    * train2017\n","        * img1.txt\n","        * img2.txt\n","    * val2017\n","        * img3.txt\n","\n","\n","txt格式 (YOLOv5)\n","\n","**class id, x, y, width, height**\n","\n","x,y,w,h 皆為normalized數值 0~1\n","```\n","45 0.479492 0.688771 0.955609 0.5955\n","45 0.736516 0.247188 0.498875 0.476417\n","50 0.637063 0.732938 0.494125 0.510583\n","45 0.339438 0.418896 0.678875 0.7815\n","49 0.646836 0.132552 0.118047 0.096937\n","49 0.773148 0.129802 0.090734 0.097229\n","49 0.668297 0.226906 0.131281 0.146896\n","49 0.642859 0.079219 0.148063 0.148062\n","```"],"metadata":{"id":"D0YtCh-4QqF2"}},{"cell_type":"markdown","source":["#### Training"],"metadata":{"id":"l35PaFblbew0"}},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"Gayhf2O6l68v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706532883637,"user_tz":-480,"elapsed":1095,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"3c9c95aa-30a5-425e-f198-82c83bd43ab3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["# 切換至yolov7 repo 資料夾\n","%cd yolov7"],"metadata":{"id":"XPY4xFJ2gbzy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706532926206,"user_tz":-480,"elapsed":937,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"d5b250d7-1f3a-4df1-9340-d55159ee3ef7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n"]}]},{"cell_type":"code","source":["# 檢查檔案列表\n","!ls"],"metadata":{"id":"Z9ktM0Bnho0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706532941131,"user_tz":-480,"elapsed":470,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"efa33723-3401-469b-b9c3-43265c34d319"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cfg\tdetect.py  hubconf.py  models\t  requirements.txt  tools\t  utils\n","data\texport.py  inference   paper\t  scripts\t    train_aux.py  YOLOv7.ipynb\n","deploy\tfigure\t   LICENSE.md  README.md  test.py\t    train.py\n"]}]},{"cell_type":"code","source":["# 安裝yolov7依賴的套件\n","!pip install -r requirements.txt"],"metadata":{"id":"v65kkQSHhdaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706532974213,"user_tz":-480,"elapsed":6314,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"be5bd3ac-ae28-4f81-dbb9-a5c88ec81271"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n","Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0+cu121)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.1)\n","Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.15.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.13.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n","Collecting thop (from -r requirements.txt (line 36))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.11.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.60.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.5.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)\n","Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 34))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.13)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.19.1 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"markdown","source":["# 修改config檔\n","\n","\n","\n","1.   data config: **data/coco.yaml** (資料設定檔)\n","    1.   刪除 ```download: bash ./scripts/get_coco.sh``` 避免下載COCO資料集\n","    2.   將train: `./coco/train2017.txt` 替換成訓練的圖片資料夾\n","    3.   nc: 80 替換成類別數 (BCCD: 3)\n","    4.   names: 替換成類別名稱['WBC', 'RBC', 'Platelets']\n","    5. 存檔\n","\n","```yaml\n","train: ../train/images # 訓練圖片資料夾\n","val: ../valid/images # 驗證圖片資料夾\n","test: ../test/images # 測試圖片資料夾 (Optional)\n","\n","# 類別數\n","nc: 3\n","\n","# 類別名稱\n","names: ['Platelets', 'RBC', 'WBC']\n","```\n","\n","2.   model config: **cfg/training/yolov7.yaml** (模型設定檔)\n","    1. nc: 80  替換成類別數\n","    2. 存檔\n","\n"],"metadata":{"id":"8UwMDxxlVLX4"}},{"cell_type":"markdown","source":["#### Training\n","\n","--data: 資料集設定檔\n","\n","--img: img size\n","\n","--cfg: 模型架構 & 設定\n","\n","--weight: 初始參數\n","\n","--name: 實驗名稱\n","\n","--hyp：超參數\n","\n","--workers: maximum number of dataloader workers"],"metadata":{"id":"SHoxCJi8pXJl"}},{"cell_type":"code","source":["!python train.py \\\n","    --workers 8 \\\n","    --device 0 \\\n","    --batch-size 8 \\\n","    --data data/coco.yaml \\\n","    --img 640 640 \\\n","    --cfg cfg/training/yolov7.yaml \\\n","    --weights '' \\\n","    --name yolov7 \\\n","    --hyp data/hyp.scratch.p5.yaml"],"metadata":{"id":"oGY3fj9hAAnq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706533411558,"user_tz":-480,"elapsed":151284,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"89213150-9859-4f93-aed3-98125bf6599d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-29 13:01:04.444384: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-29 13:01:04.444443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-29 13:01:04.445928: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-29 13:01:04.453667: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-29 13:01:05.423401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR 🚀 0e1e97f torch 2.1.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Namespace(weights='', cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=300, batch_size=8, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='yolov7', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', world_size=1, global_rank=-1, save_dir='runs/train/yolov7', total_batch_size=8)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     44944  models.yolo.IDetect                     [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37207344 parameters, 37207344 gradients, 105.1 GFLOPS\n","\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train/labels' images and labels... 255 found, 0 missing, 0 empty, 0 corrupted: 100% 255/255 [00:00<00:00, 2487.26it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '../valid/labels' images and labels... 73 found, 0 missing, 0 empty, 0 corrupted: 100% 73/73 [00:00<00:00, 875.61it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../valid/labels.cache\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.91, Best Possible Recall (BPR) = 0.9994\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to runs/train/yolov7\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     0/299     1.53G   0.06802     1.724   0.02335     1.815       240       640: 100% 32/32 [00:33<00:00,  1.03s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:12<00:00,  2.54s/it]\n","                 all          73         967       0.668      0.0602    0.000727    9.66e-05\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     1/299     6.69G   0.06898    0.4014   0.02335    0.4938       311       640: 100% 32/32 [00:15<00:00,  2.13it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:09<00:00,  1.87s/it]\n","                 all          73         967       0.335      0.0648    0.000861    0.000111\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     2/299      7.6G   0.06897    0.1858   0.02334    0.2781       198       640: 100% 32/32 [00:14<00:00,  2.17it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:09<00:00,  1.89s/it]\n","                 all          73         967       0.671     0.00463    0.000872    0.000155\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     3/299      7.6G   0.06934    0.1049   0.02332    0.1976       272       640: 100% 32/32 [00:14<00:00,  2.20it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:08<00:00,  1.79s/it]\n","                 all          73         967       0.338     0.00926    0.000927     0.00016\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     4/299      7.6G   0.07031   0.08635   0.02332      0.18       312       640:   9% 3/32 [00:02<00:22,  1.32it/s]\n","Traceback (most recent call last):\n","  File \"/content/yolov7/train.py\", line 609, in <module>\n","    train(hyp, opt, device, tb_writer)\n","  File \"/content/yolov7/train.py\", line 385, in train\n","    pbar.set_description(s)\n","  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1383, in set_description\n","    def set_description(self, desc=None, refresh=True):\n","KeyboardInterrupt\n"]}]},{"cell_type":"markdown","source":["在 **runs/train/實驗名稱**中會存放每次訓練的結果與參數檔案"],"metadata":{"id":"AeuvshL-ZDBE"}},{"cell_type":"markdown","source":["#### Transfer learning\n","\n","使用官方COCO pre-trained model做finetune"],"metadata":{"id":"kIf2SplRZVzx"}},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"6k9Yp180N3kW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706533509674,"user_tz":-480,"elapsed":460,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"e2330846-4206-434f-f157-a020380f4c1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n"]}]},{"cell_type":"code","source":["# 下載官方pre-trained參數\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"],"metadata":{"id":"JBWEpuDq3SHn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706533530278,"user_tz":-480,"elapsed":4628,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"2d030e06-f6eb-4b1d-b1de-d13cd51571fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-29 13:05:25--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240129T130525Z&X-Amz-Expires=300&X-Amz-Signature=214864707d45414047cc56a09756ed0adc81faa39d0272b9024f7e6194d1b8d8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n","--2024-01-29 13:05:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240129T130525Z&X-Amz-Expires=300&X-Amz-Signature=214864707d45414047cc56a09756ed0adc81faa39d0272b9024f7e6194d1b8d8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75587165 (72M) [application/octet-stream]\n","Saving to: ‘yolov7.pt’\n","\n","yolov7.pt           100%[===================>]  72.08M   376MB/s    in 0.2s    \n","\n","2024-01-29 13:05:29 (376 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n","\n"]}]},{"cell_type":"code","source":["# finetune yolov7-p5 models\n","# 使用官方pretrained 參數\n","# --weights 參數檔路徑\n","!python train.py \\\n","    --workers 8 \\\n","    --device 0 \\\n","    --batch-size 8 \\\n","    --data data/coco.yaml \\\n","    --img 640 640 \\\n","    --cfg cfg/training/yolov7.yaml \\\n","    --weights 'yolov7.pt' \\\n","    --name yolov7-transfer \\\n","    --hyp data/hyp.scratch.custom.yaml\n","\n","# finetune yolov7-w6 models\n","# !python train_aux.py \\\n","#     --workers 8 \\\n","#     --device 0 \\\n","#     --batch-size 16 \\\n","#     --data data/custom.yaml \\\n","#     --img 1280 1280 \\\n","#     --cfg cfg/training/yolov7-w6-custom.yaml \\\n","#     --weights 'yolov7-w6_training.pt' \\\n","#     --name yolov7-w6-custom \\\n","#     --hyp data/hyp.scratch.custom.yaml"],"metadata":{"id":"DAexQHCMluEP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706533804482,"user_tz":-480,"elapsed":177844,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"87b3e3e5-92a4-49a6-be3c-3ba5a160663a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-29 13:07:08.476866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-29 13:07:08.476915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-29 13:07:08.478209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-29 13:07:08.485198: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-29 13:07:09.590723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR 🚀 0e1e97f torch 2.1.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Namespace(weights='yolov7.pt', cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=300, batch_size=8, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='yolov7-transfer', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', world_size=1, global_rank=-1, save_dir='runs/train/yolov7-transfer', total_batch_size=8)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     44944  models.yolo.IDetect                     [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37207344 parameters, 37207344 gradients, 105.1 GFLOPS\n","\n","Transferred 552/566 items from yolov7.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train/labels.cache' images and labels... 255 found, 0 missing, 0 empty, 0 corrupted: 100% 255/255 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '../valid/labels.cache' images and labels... 73 found, 0 missing, 0 empty, 0 corrupted: 100% 73/73 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.91, Best Possible Recall (BPR) = 0.9994\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to runs/train/yolov7-transfer\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     0/299     1.63G   0.06845     1.647   0.02341     1.739       164       640: 100% 32/32 [00:29<00:00,  1.07it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:13<00:00,  2.64s/it]\n","                 all          73         967      0.0116       0.222     0.00229    0.000359\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     1/299     6.67G    0.0674    0.3582   0.02341     0.449       107       640: 100% 32/32 [00:15<00:00,  2.10it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:09<00:00,  1.85s/it]\n","                 all          73         967      0.0225       0.312      0.0107     0.00196\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     2/299     7.57G   0.06822    0.1437   0.02338    0.2354       118       640: 100% 32/32 [00:15<00:00,  2.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:09<00:00,  1.99s/it]\n","                 all          73         967      0.0356       0.252      0.0244     0.00514\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     3/299     7.58G   0.06844   0.07011   0.02336    0.1619       149       640: 100% 32/32 [00:15<00:00,  2.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:04<00:00,  1.09it/s]\n","                 all          73         967      0.0669       0.245       0.056      0.0139\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     4/299     7.58G   0.06857    0.0472   0.02333    0.1391       156       640: 100% 32/32 [00:14<00:00,  2.20it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:02<00:00,  2.33it/s]\n","                 all          73         967       0.128        0.25       0.112      0.0299\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     5/299     7.58G   0.06768   0.03903   0.02327      0.13       168       640: 100% 32/32 [00:15<00:00,  2.11it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:01<00:00,  2.82it/s]\n","                 all          73         967        0.14       0.263       0.115      0.0311\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     6/299     7.58G   0.06811   0.04282    0.0232    0.1341       254       640:  12% 4/32 [00:02<00:14,  1.96it/s]\n","Traceback (most recent call last):\n","  File \"/content/yolov7/train.py\", line 609, in <module>\n","    train(hyp, opt, device, tb_writer)\n","  File \"/content/yolov7/train.py\", line 362, in train\n","    loss, loss_items = compute_loss_ota(pred, targets.to(device), imgs)  # loss scaled by batch_size\n","KeyboardInterrupt\n"]}]},{"cell_type":"markdown","source":["#### Testing"],"metadata":{"id":"mCVzRGjbaISk"}},{"cell_type":"code","source":["# 下載BCCD pre-trained model\n","!wget https://github.com/taipingeric/MIP/releases/download/yolov7-bccd/yolov7_bccd.pt"],"metadata":{"id":"CsDBqazED2T8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706533834993,"user_tz":-480,"elapsed":22426,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"d3f7979b-a6f3-48c4-ad32-1c1080fb0adb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-29 13:10:12--  https://github.com/taipingeric/MIP/releases/download/yolov7-bccd/yolov7_bccd.pt\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/678249561/0f05301e-3209-470c-8fb1-8b4c41b59629?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240129T131012Z&X-Amz-Expires=300&X-Amz-Signature=361faaa133f6271607466e728a8de8587d0fc12f6710dd5cbd3b3344bf452ac0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=678249561&response-content-disposition=attachment%3B%20filename%3Dyolov7_bccd.pt&response-content-type=application%2Foctet-stream [following]\n","--2024-01-29 13:10:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/678249561/0f05301e-3209-470c-8fb1-8b4c41b59629?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240129T131012Z&X-Amz-Expires=300&X-Amz-Signature=361faaa133f6271607466e728a8de8587d0fc12f6710dd5cbd3b3344bf452ac0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=678249561&response-content-disposition=attachment%3B%20filename%3Dyolov7_bccd.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 298475434 (285M) [application/octet-stream]\n","Saving to: ‘yolov7_bccd.pt’\n","\n","yolov7_bccd.pt      100%[===================>] 284.65M  16.3MB/s    in 18s     \n","\n","2024-01-29 13:10:34 (15.4 MB/s) - ‘yolov7_bccd.pt’ saved [298475434/298475434]\n","\n"]}]},{"cell_type":"code","source":["# --weights: 測試參數檔案\n","# --task: 任務種類 test, valid, train\n","\n","!python test.py \\\n","    --task \"test\" \\\n","    --data data/coco.yaml \\\n","    --img 640 \\\n","    --batch 8 \\\n","    --conf 0.001 \\\n","    --iou 0.65 \\\n","    --device 0 \\\n","    --weights \"/content/yolov7/runs/train/yolov7-transfer/weights/best.pt\" \\\n","    --name yolov7_640_val"],"metadata":{"id":"ZdeRQeEeaHpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python test.py \\\n","    --task \"test\" \\\n","    --data data/coco.yaml \\\n","    --img 640 \\\n","    --batch 8 \\\n","    --conf 0.001 \\\n","    --iou 0.65 \\\n","    --device 0 \\\n","    --weights \"/content/yolov7/yolov7_bccd.pt\" \\\n","    --name yolov7_640_val"],"metadata":{"id":"Ju9sY-pCDqgl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706533942067,"user_tz":-480,"elapsed":26028,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"103a23f1-831e-4b54-8de7-612446b985b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/yolov7_bccd.pt'], data='data/coco.yaml', batch_size=8, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='0', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project='runs/test', name='yolov7_640_val', exist_ok=False, no_trace=False)\n","YOLOR 🚀 0e1e97f torch 2.1.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","IDetect.fuse\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","\u001b[34m\u001b[1mtest: \u001b[0mScanning '../test/labels' images and labels... 36 found, 0 missing, 0 empty, 0 corrupted: 100% 36/36 [00:00<00:00, 862.41it/s]\n","\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: ../test/labels.cache\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:02<00:00,  1.78it/s]\n","                 all          36         471       0.705       0.876       0.837       0.513\n","           Platelets          36          36       0.516       0.861       0.686       0.321\n","                 RBC          36         398       0.655       0.849       0.862       0.525\n","                 WBC          36          37       0.944       0.917       0.964       0.691\n","Speed: 23.4/21.5/44.9 ms inference/NMS/total per 640x640 image at batch-size 8\n","\n","Evaluating pycocotools mAP... saving runs/test/yolov7_640_val/yolov7_bccd_predictions.json...\n","loading annotations into memory...\n","pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n","Results saved to runs/test/yolov7_640_val\n"]}]},{"cell_type":"markdown","source":["#### Inference"],"metadata":{"id":"VhwtIM9VZb3S"}},{"cell_type":"code","source":["# 下載BCCD pre-trained model\n","!wget https://github.com/taipingeric/MIP/releases/download/yolov7-bccd/yolov7_bccd.pt"],"metadata":{"id":"PGRyBkXwarLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# source: 資料夾or圖片路徑\n","# save-txt: 輸出txt結果\n","# save-conf: 在txt中輸出box confidence\n","\n","# 預測全部test/images資料夾\n","# !python detect.py \\\n","#     --weights \"/content/yolov7/yolov7_bccd.pt\" \\\n","#     --conf 0.25 \\\n","#     --img-size 640 \\\n","#     --source '/content/test/images/' \\\n","#     --save-txt --save-conf\n","\n","# 預測單一圖片/影片\n","!python detect.py \\\n","    --weights \"/content/yolov7/yolov7_bccd.pt\" \\\n","    --conf 0.25 \\\n","    --img-size 640 \\\n","    --source '/content/test/images/BloodImage_00038_jpg.rf.63d04b5c9db95f32fa7669f72e4903ca.jpg' \\\n","    --save-txt --save-conf"],"metadata":{"id":"TUP_hZyFLlbU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706534172990,"user_tz":-480,"elapsed":20129,"user":{"displayName":"CY Li","userId":"11560903483017836470"}},"outputId":"e1a85e3f-e338-49db-bc98-803e2074f2d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/yolov7_bccd.pt'], source='/content/test/images/BloodImage_00038_jpg.rf.63d04b5c9db95f32fa7669f72e4903ca.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=True, save_conf=True, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 0e1e97f torch 2.1.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","IDetect.fuse\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n"," The image with the result is saved in: runs/detect/exp/BloodImage_00038_jpg.rf.63d04b5c9db95f32fa7669f72e4903ca.jpg\n","Done. (0.733s)\n"]}]},{"cell_type":"code","source":["# 使用官方參數檔預測\n","!python detect.py \\\n","    --weights \"/content/yolov7/yolov7.pt\" \\\n","    --conf 0.25 \\\n","    --img-size 640 \\\n","    --source inference/images/horses.jpg \\\n","    --save-txt --save-conf"],"metadata":{"id":"_b6HkIhV8yAd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["在runs/detect/exp*/  看照片偵測後的成果"],"metadata":{"id":"nB_nGRWOZsrK"}},{"cell_type":"markdown","source":["#### More configs\n","\n","cfg/training/yolov7.yaml"],"metadata":{"id":"RG9OHThspfmv"}},{"cell_type":"markdown","source":["\n","```yaml\n","# parameters\n","nc: 80  # number of classes\n","depth_multiple: 1.0  # model depth multiple\n","width_multiple: 1.0  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [12,16, 19,36, 40,28]  # P3/8\n","  - [36,75, 76,55, 72,146]  # P4/16\n","  - [142,110, 192,243, 459,401]  # P5/32\n","\n","# yolov7 backbone\n","# Conv: ch_out, kernel, stride, padding, groups\n","backbone:\n","  # [from, number, module, args]\n","  # Stage 0\n","  [[-1, 1, Conv, [32, 3, 1]],  # 0\n","   # Stage 1\n","   [-1, 1, Conv, [64, 3, 2]],  # 1-P1/2\n","   [-1, 1, Conv, [64, 3, 1]],\n","   # Stage 2\n","   [-1, 1, Conv, [128, 3, 2]],  # 3-P2/4\n","   # ELAN, 256\n","   [-1, 1, Conv, [64, 1, 1]],  # -6\n","   [-2, 1, Conv, [64, 1, 1]],  # -5\n","   [-1, 1, Conv, [64, 3, 1]],\n","   [-1, 1, Conv, [64, 3, 1]],  # -3\n","   [-1, 1, Conv, [64, 3, 1]],\n","   [-1, 1, Conv, [64, 3, 1]],  # -1\n","   [[-1, -3, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [256, 1, 1]],  # 11\n","   # Stage 3\n","   # Down c_out = 256\n","   [-1, 1, MP, []], # MP: MaxPooling\n","   [-1, 1, Conv, [128, 1, 1]],\n","   [-3, 1, Conv, [128, 1, 1]],\n","   [-1, 1, Conv, [128, 3, 2]],\n","   [[-1, -3], 1, Concat, [1]],  # 16-P3/8\n","   # ELAN, 512\n","   [-1, 1, Conv, [128, 1, 1]],\n","   [-2, 1, Conv, [128, 1, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [[-1, -3, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [512, 1, 1]],  # 24\n","   # Stage 4\n","   [-1, 1, MP, []],\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-3, 1, Conv, [256, 1, 1]],\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, -3], 1, Concat, [1]],  # 29-P4/16\n","   # ELAN, 1024\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-2, 1, Conv, [256, 1, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [[-1, -3, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [1024, 1, 1]],  # 37\n","   # Stage 5\n","   [-1, 1, MP, []],\n","   [-1, 1, Conv, [512, 1, 1]],\n","   [-3, 1, Conv, [512, 1, 1]],\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, -3], 1, Concat, [1]],  # 42-P5/32\n","   # ELAN, 1024\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-2, 1, Conv, [256, 1, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [[-1, -3, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [1024, 1, 1]],  # 50\n","  ]\n","\n","# yolov7 head\n","head:\n","  # Stage: 5\n","  [[-1, 1, SPPCSPC, [512]], # 51\n","   # Stage 4\n","   # *2 Up, 512\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [37, 1, Conv, [256, 1, 1]], # route backbone P4\n","   [[-1, -2], 1, Concat, [1]],\n","   # ELAN, 256\n","   [-1, 1, Conv, [256, 1, 1]], # -6\n","   [-2, 1, Conv, [256, 1, 1]], # -5\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [[-1, -2, -3, -4, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [256, 1, 1]], # 63\n","   # Stage 3\n","   # *2 Up, 512\n","   [-1, 1, Conv, [128, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [24, 1, Conv, [128, 1, 1]], # route backbone P3\n","   [[-1, -2], 1, Concat, [1]],\n","   # ELAN, 128\n","   [-1, 1, Conv, [128, 1, 1]],\n","   [-2, 1, Conv, [128, 1, 1]],\n","   [-1, 1, Conv, [64, 3, 1]],\n","   [-1, 1, Conv, [64, 3, 1]],\n","   [-1, 1, Conv, [64, 3, 1]],\n","   [-1, 1, Conv, [64, 3, 1]],\n","   [[-1, -2, -3, -4, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [128, 1, 1]], # 75\n","   # Stage 4\n","   # Down, 512\n","   [-1, 1, MP, []],\n","   [-1, 1, Conv, [128, 1, 1]],\n","   [-3, 1, Conv, [128, 1, 1]],\n","   [-1, 1, Conv, [128, 3, 2]],\n","   [[-1, -3, 63], 1, Concat, [1]],\n","   # ELAN, 256\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-2, 1, Conv, [256, 1, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [-1, 1, Conv, [128, 3, 1]],\n","   [[-1, -2, -3, -4, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [256, 1, 1]], # 88\n","   # Stage 5\n","   # Down, 1024\n","   [-1, 1, MP, []],\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-3, 1, Conv, [256, 1, 1]],\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, -3, 51], 1, Concat, [1]],\n","   # ELAN, 512\n","   [-1, 1, Conv, [512, 1, 1]],\n","   [-2, 1, Conv, [512, 1, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [-1, 1, Conv, [256, 3, 1]],\n","   [[-1, -2, -3, -4, -5, -6], 1, Concat, [1]],\n","   [-1, 1, Conv, [512, 1, 1]], # 101\n","\n","   [75, 1, RepConv, [256, 3, 1]],\n","   [88, 1, RepConv, [512, 3, 1]],\n","   [101, 1, RepConv, [1024, 3, 1]],\n","\n","   [[102,103,104], 1, IDetect, [nc, anchors]],   # Detect(P3, P4, P5)\n","  ]\n","\n","```"],"metadata":{"id":"ULpLXTAun9-y"}},{"cell_type":"markdown","source":["#### Important Files\n","\n","yolov7\n","\n","\n","\n","*   train.py: 訓練script\n","*   test.py: 測試script\n","* detect.py: 偵測圖片或影片\n","* cfg/: 模型架構設定檔\n","* data/: 資料集設定檔\n","    * coco.yaml: 範例格式\n","    * hyp.*.yaml: 超參數設定\n","* models/: 模型程式碼\n","    * yolo.py\n","        * parse_model: yaml config轉模型\n","    * common.py: 網路層\n","* paper/: 論文pdf (含附錄)\n","* tools/: demo 筆記本檔\n","* utils/: 其他程式碼\n"],"metadata":{"id":"asCFpzHCpnR-"}},{"cell_type":"code","source":[],"metadata":{"id":"eT5A6EtvcrxR"},"execution_count":null,"outputs":[]}]}