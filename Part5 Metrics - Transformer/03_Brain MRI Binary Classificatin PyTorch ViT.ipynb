{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO5wjieyTUTFLGQJm/Sl+JP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Brain MRI Binary Classificatin PyTorch ViT"],"metadata":{"id":"RPGIfASwQcer"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zg7SyP0CM2td"},"outputs":[],"source":["# download dataset from\n","!pip install --upgrade gdown==v4.6.3\n","!gdown --fuzzy 18RfTvv5NBKuUgMDJjxXb7BLYz31sT_aH --output brain.zip\n","# unzip\n","!unzip -q brain.zip"]},{"cell_type":"code","source":["import cv2\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from glob import glob\n","from tqdm.auto import tqdm\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"nF0BuAMYNEbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE = 256\n","class_map = {\n","    'no': 0,\n","    'yes': 1\n","}\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"tkY674XzNNH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read single image\n","img_paths = sorted(glob('./brain/*/*.jpg') + glob('./brain/*/*.JPG') + glob('./brain/*/*.jpeg'))"],"metadata":{"id":"w20P6h_KNSlK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# number of images\n","len(img_paths)"],"metadata":{"id":"wclZ0gz1NT0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show image\n","path = img_paths[-9]\n","img = Image.open(path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n","print(path, img.size)\n","plt.imshow(img)"],"metadata":{"id":"N6KhMc6kNVES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract img class\n","img_path = img_paths[-9]\n","print(img_path)\n","# read label\n","cls = img_path.split('/')[-2]\n","print(cls)\n","# cls idx\n","print(class_map[cls])"],"metadata":{"id":"mNq69KfJNYxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Dataset, Dataloader"],"metadata":{"id":"J0Z8wglKODB8"}},{"cell_type":"code","source":["class BrainDataset(torch.utils.data.Dataset):\n","    def __init__(self, paths, transform):\n","        self.paths = paths\n","        self.transform = transform\n","        self.class_map = {\n","            'no': 0,\n","            'yes': 1\n","        }\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        path = self.paths[idx]\n","        img = Image.open(path).convert(\"RGB\")\n","        img = self.transform(img)\n","\n","        cls = path.split('/')[-2]\n","        label = self.class_map[cls]\n","        label = torch.tensor(label, dtype=torch.long)\n","        return img, label"],"metadata":{"id":"Kel5jU2qNwcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_paths, val_paths = train_test_split(\n","    img_paths,\n","    test_size=0.2,\n","    random_state=5566\n",")"],"metadata":{"id":"B-gKMC2fOxtX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transforms = torchvision.models.ViT_B_16_Weights.DEFAULT.transforms()\n","\n","train_ds = BrainDataset(train_paths, transforms)\n","val_ds = BrainDataset(train_paths, transforms)"],"metadata":{"id":"MSOuAvWpPOw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(transforms)"],"metadata":{"id":"TQwclFnIBA1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, label = train_ds[0]\n","img.shape, label"],"metadata":{"id":"CwAHo3ggP43K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.subplot(1, 2, 1)\n","plt.imshow(img.permute(1, 2, 0))\n","img_raw = img.numpy().transpose(1, 2, 0) # (3, 256, 256) -> (256, 256, 3)\n","mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])\n","img_raw = std * img_raw + mean\n","img_raw = np.clip(img_raw, 0, 1)\n","print(img_raw.shape)\n","plt.subplot(1, 2, 2)\n","plt.imshow(img_raw)\n","plt.show()"],"metadata":{"id":"8lhGEzcJA4UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BS = 32\n","train_loader = torch.utils.data.DataLoader(train_ds, BS, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_ds, BS)"],"metadata":{"id":"qlRDwWo_RSKY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"hfRk1BAhQX4z"}},{"cell_type":"code","source":["model = torchvision.models.vit_b_16(\n","    weights=torchvision.models.ViT_B_16_Weights.DEFAULT\n",")\n","\n","# freeze encoder\n","for p in model.parameters():\n","    p.requires_grad = False\n","\n","model.heads = nn.Sequential(\n","    nn.Linear(in_features=768, out_features=2)\n",")"],"metadata":{"id":"w2C16INLP-rW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = torch.randn(1, 3, 224, 224)\n","outputs = model(inputs)\n","outputs.shape"],"metadata":{"id":"OJQZVJEBQhK5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training"],"metadata":{"id":"IEfiZj2BQtHl"}},{"cell_type":"code","source":["model = model.to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())"],"metadata":{"id":"RyN4BX-RQrwa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset) # number of samples\n","    num_batches = len(dataloader) # batches per epoch\n","\n","    model.train() # to training mode.\n","    epoch_loss, epoch_correct = 0, 0\n","    for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n","        x, y = x.to(device), y.to(device) # move data to GPU\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Compute prediction loss\n","        pred = model(x)\n","        loss = loss_fn(pred, y)\n","\n","        # Optimization by gradients\n","        loss.backward() # backpropagation to compute gradients\n","        optimizer.step() # update model params\n","\n","        # write to logs\n","        epoch_loss += loss.item() # tensor -> python value\n","        # (N, Class)\n","        epoch_correct += (pred.argmax(dim=1) == y).sum().item()\n","\n","    # return avg loss of epoch, acc of epoch\n","    return epoch_loss/num_batches, epoch_correct/size\n","\n","\n","def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset) # number of samples\n","    num_batches = len(dataloader) # batches per epoch\n","\n","    model.eval() # model to test mode.\n","    epoch_loss, epoch_correct = 0, 0\n","\n","    # No gradient for test data\n","    with torch.no_grad():\n","        for batch_i, (x, y) in enumerate(dataloader):\n","            x, y = x.to(device), y.to(device)\n","\n","            # Compute prediction loss\n","            pred = model(x)\n","            loss = loss_fn(pred, y)\n","\n","            # write to logs\n","            epoch_loss += loss.item()\n","            epoch_correct += (pred.argmax(1) == y).sum().item()\n","\n","    return epoch_loss/num_batches, epoch_correct/size\n","\n","EPOCHS = 100\n","logs = {\n","    'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []\n","}\n","# Earlystopping\n","patience = 5\n","counter = 0\n","best_loss = np.inf\n","\n","for epoch in tqdm(range(EPOCHS)):\n","    train_loss, train_acc = train(train_loader, model, loss_fn, optimizer)\n","    val_loss, val_acc = test(val_loader, model, loss_fn)\n","\n","    print(f'EPOCH: {epoch:04d} \\\n","    train_loss: {train_loss:.4f}, train_acc: {train_acc:.3f} \\\n","    val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f} ')\n","\n","    logs['train_loss'].append(train_loss)\n","    logs['train_acc'].append(train_acc)\n","    logs['val_loss'].append(val_loss)\n","    logs['val_acc'].append(val_acc)\n","\n","\n","    torch.save(model.state_dict(), \"last.pth\")\n","    # chcek improvement\n","    if val_loss < best_loss:\n","        counter = 0\n","        best_loss = val_loss\n","        torch.save(model.state_dict(), \"best.pth\")\n","    else:\n","        counter += 1\n","    if counter >= patience:\n","        print(\"Earlystop!\")\n","        break"],"metadata":{"id":"0yvEUkacQ7DN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluation"],"metadata":{"id":"20hH88JySCIr"}},{"cell_type":"code","source":["from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n","    ConfusionMatrixDisplay,\n","    recall_score, # sensitivity\n","    precision_score,\n","    f1_score,\n","    roc_curve,\n","    auc,\n",")\n","import pandas as pd"],"metadata":{"id":"eIeIqq15URl2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('best.pth'))\n","_ = model.eval().to(device)"],"metadata":{"id":"uKGTxgU9RP-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inference\n","y_pred = []\n","y_pred_raw = []\n","y_true = []\n","\n","with torch.no_grad():\n","    for x, y in tqdm(val_loader):\n","        x = x.to(device)\n","        pred = model(x) # logits\n","        pred = nn.functional.softmax(pred, dim=1) # apply softmax to logits\n","        y_pred_raw.append(pred[:, 1]) # probability of class 1\n","        y_pred.append(pred.argmax(dim=1))\n","        y_true.append(y)\n","\n","y_pred = torch.cat(y_pred, dim=0).cpu().numpy()\n","y_pred_raw = torch.cat(y_pred_raw, dim=0).cpu().numpy()\n","y_true = torch.cat(y_true, dim=0).cpu().numpy()"],"metadata":{"id":"s3Ez4m22SZTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred.shape, y_pred_raw.shape, y_true.shape"],"metadata":{"id":"iTCA86yMTVnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred[:3], y_pred_raw[:3], y_true[:3]"],"metadata":{"id":"15Xv_TCgTidL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# classification_report\n","print(classification_report(y_true, y_pred,\n","                            target_names=[\"NO\", \"YES\"],\n","                            digits=3))"],"metadata":{"id":"pWnQ_463T_3g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Sensitivity:\", recall_score(y_true, y_pred))\n","print(\"Precision:  \", precision_score(y_true, y_pred))\n","print(\"F1 score:   \", f1_score(y_true, y_pred))"],"metadata":{"id":"2kEu0_RIhY2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion matrix:\n","#   row: Ground truth\n","#   column: predict\n","\n","cm = confusion_matrix(y_true, y_pred)\n","print(cm)"],"metadata":{"id":"USdY8pNyUVCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(\n","    confusion_matrix=cm,\n","    display_labels=[\"No\", \"Yes\"]\n",")\n","disp.plot()\n","plt.show()"],"metadata":{"id":"WOZ-w-9-US8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# y_pred_raw: 0~1\n","fp_rate, tp_rate, threshold = roc_curve(\n","    y_true, y_pred_raw\n",")\n","\n","df = pd.DataFrame({\n","    'FPR': fp_rate,\n","    'TPR': tp_rate,\n","    'Threshold': threshold\n","})\n","df"],"metadata":{"id":"lmPEQlTOUWlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AUC score\n","auc_score = auc(fp_rate, tp_rate)\n","print(f'AUC: {auc_score:.4f}')"],"metadata":{"id":"O7jm2_IqUjec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC curve\n","plt.xlabel('False Positive Rate (FPR) 1-Specificity')\n","plt.ylabel('True Positive Rate (TPR) Sensitivity')\n","plt.plot(fp_rate, tp_rate, marker=\"^\")\n","plt.title('ROC curve')\n","plt.show()"],"metadata":{"id":"hPML5ZGIUm1s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lo7VLGIvUolW"},"execution_count":null,"outputs":[]}]}